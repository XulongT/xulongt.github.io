---
permalink: /
title: "Xulong Tang (Ben)"
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# 🐲 About Xulong
Hello! I'm Xulong Tang, you can call me Ben!

I am a second-year PhD student in the Department of Computer Science at The University of Texas at Dallas.

**Research Interests**: 
- 3D Human Dance Motion Generation
- Extended Reality (XR), including Virtual Reality, Augmented Reality, and Mixed Reality
- Computer Vision
- Multimedia Retrieval
- Multimodal Learning

In addition to my research, I am also a game developer:

I have used Unity to create a VR educational game for teaching children about the universe at the [Sci-Tech Discovery Center](https://mindstretchingfun.org/). 

I have also contributed to the development of an unreleased third-person survival shooter game using Unreal Engine and C++, where I was responsible for gameplay and user interface.

# 🔥 News
- *2025.09*: &nbsp;🎉🎉 One paper was accepted at NeurIPS 2025.
- *2025.07*: &nbsp;🎉🎉 One paper was accepted at ACM Multimedia 2025.
- *2024.06*: &nbsp;🎉🎉 Two papers were accepted at ICMR 2024.
- *2024.01*: &nbsp;🎉🎉 Started my PhD at The University of Texas at Dallas.


# 📝 Publications 

**NeurIPS 2025**

*MEGADance: Mixture-of-Experts Architecture for Genre-Aware 3D Dance Generation*

[[PDF](https://arxiv.org/abs/2505.17543)]
[[CODE](https://github.com/XulongT/MEGADance)]

Kaixing Yang\*, Xulong Tang\*, Ziqiao Peng, Yuxuan Hu, Jun He, Hongyan Liu

\*: Equal contribution

**ACM MM 2025**

*CoheDancers: Interactive Group Dance Generation via Music-Driven Coherence Decomposition*

[[PDF](https://arxiv.org/abs/2412.19123)]
[[CODE](https://github.com/XulongT/CoheDancers)]

Kaixing Yang\*, Xulong Tang\*, Haoyu Wu, Qinliang Xue, Biao Qin, Hongyan Liu, Zhaoxin Fan

\*: Equal contribution

**ICMR 2024**

*CoDancers: Music-Driven Coherent Group Dance Generation with Choreographic Unit*

[[PDF](https://dl.acm.org/doi/abs/10.1145/3652583.3657998)]
[[CODE](https://github.com/XulongT/CoDancers)]

Kaixing Yang\*, Xulong Tang\*, Ran Diao, Hongyan Liu, Jun He, Zhaoxin Fan

\*: Equal contribution

**ICMR 2024**

*BeatDance: A Beat-Based Model-Agnostic Contrastive Learning Framework for Music-Dance Retrieval*

[[PDF](https://dl.acm.org/doi/abs/10.1145/3652583.3658045)]
[[CODE](https://github.com/XulongT/BeatDance)]

Kaixing Yang, Xukun Zhou, Xulong Tang, Ran Diao, Hongyan Liu, Jun He, Zhaoxin Fan

# 📖 Education
- *2024.01 - present*, PhD in Computer Science, The University of Texas at Dallas, Richardson, Texas
- *2023.09 - 2024.01*, Master of Computer Science, The University of Texas at Dallas, Richardson, Texas
- *2018.09 - 2022.06*, Undergraduate, Xidian University, Xi'an, China



# 💻 Internships
- *2021.12 - 2022.06*, Unreal Engine Developer, Shengqu Games, Shanghai, China
